"""
Flight Price Estimation - Random Forest Regression 
Automatically generated by Colab.
"""

# Importing Library
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
import warnings
import math


"""### DATA EXPLORATION"""

df = pd.read_csv('Clean_Dataset.csv')
df

# Exploring and Summarizing Data Distributions
df.airline.value_counts()
df.source_city.value_counts()
df.destination_city.value_counts()
df.departure_time.value_counts()
df.arrival_time.value_counts()
df.stops.value_counts()
df['class'].value_counts()
df['duration'].min()
df['duration'].max()
df['duration'].median()


"""### PREPROCESSING DATA"""

# Dropping Unnecessary Columns (Unnamed: 0 and flight)
df = df.drop(['Unnamed: 0', 'flight'], axis = 1)

# Converting 'class' Feature to Binary
df['class'] = df['class'].map({'Economy': 0, 'Business': 1})

# Converting Categorical 'stops' Feature to Numerical
df['stops'] = pd.factorize(df['stops'])[0]

# One-Hot Encoding of Categorical Features
df = df.join(pd.get_dummies(df.airline, prefix='airline', dtype=int)).drop('airline', axis=1)
df = df.join(pd.get_dummies(df.source_city, prefix='source', dtype=int)).drop('source_city', axis=1)
df = df.join(pd.get_dummies(df.destination_city, prefix='destination', dtype=int)).drop('destination_city', axis=1)
df = df.join(pd.get_dummies(df.arrival_time, prefix='arrival', dtype=int)).drop('arrival_time', axis=1)
df = df.join(pd.get_dummies(df.departure_time, prefix='departure', dtype=int)).drop('departure_time', axis=1)

df
df.info()


"""### TRAINING REGRESSION MODEL"""

# Preparing Data for Random Forest Regression
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

X, y = df.drop('price', axis=1), df['price']

# Splitting Data into Training and Testing Sets (20% testing and 80% training)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Data Modeling
reg = RandomForestRegressor(n_jobs=-1)
reg.fit(X_train, y_train)


"""### EVALUATING DATA"""

# R2
reg.score(X_test, y_test)

#Generating Predictions with the Regression Model
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
y_pred = reg.predict(X_test)

# Regression Model Performance Metrics
print('MAE:', mean_absolute_error(y_test, y_pred))
print('MSE:', mean_squared_error(y_test, y_pred))
print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))
print('R2:', r2_score(y_test, y_pred))

#Scatter Plot of Actual vs Predicted Values
plt.scatter(y_test, y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted')
plt.show()

df.price.describe()

# Identifying and Sorting Feature Importances
importances = dict(zip(reg.feature_names_in_, reg.feature_importances_))
sorted_importances = dict(sorted(importances.items(), key=lambda x: x[1], reverse=True))

sorted_importances

# Visualizing Top 10 Feature Importances
plt.figure(figsize = (10,6))
top_importances = sorted_importances[:10]
plt.bar([x[0] for x in sorted_importances], [x[1] for x in sorted_importances])
plt.xticks(rotation=90)
plt.show()

